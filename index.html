<!DOCTYPE html>
<html lang="en">
    <head>
        <meta name="generator" content="HTML Tidy for HTML5 for Apple macOS version 5.6.0">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="description" content="AI and Security Workshop (AISec)">
        <meta name="keywords" content="Deep Learning, Machine Learning, Security, Adversarial Examples, Attacks, Intrusion Detection, Program Analysis, Malware, Botnets, Vulnerability, Phishing, Forensics, Neural Networks, Recurrent Networks, Generative Adversarial Networks, AISec">
        <meta name="author" content="AISec Chairs">
        <title>17th ACM Workshop on Artificial Intelligence and Security (AISec 2024)</title>
        <link
            href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css"
            rel="stylesheet"
            integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ"
            crossorigin="anonymous"
        >
        <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=K2D:400,700" rel="stylesheet" type="text/css">
        <!-- Custom styles for this template -->
        <link href="css/agency.css" rel="stylesheet">
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-QDQDHN7F62"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-QDQDHN7F62');
        </script>
    </head>
    <body id="page-top">
        <!-- Navigation -->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">AISec 2024</a>
                <button
                    class="navbar-toggler navbar-toggler-right"
                    type="button"
                    data-toggle="collapse"
                    data-target="#navbarResponsive"
                    aria-controls="navbarResponsive"
                    aria-expanded="false"
                    aria-label="Toggle navigation"
                >Menu</button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#page-top">Home</a>
                        </li>
                        <!-- <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#keynote">Keynotes</a>
                        </li> -->
                        <!-- <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#programme">Programme</a>
                        </li> -->
                        <!-- <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#accepted">Accepted Papers</a>
                        </li> -->
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#cfp">Call for Papers</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#award">Best Paper Award</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" href="#committee">Committee</a>
                        </li>
                        <li class="nav-item dropdown">
                            <li class="nav-item dropdown">
                                <a
                                    class="nav-link dropdown-toggle"
                                    href="#"
                                    role="button"
                                    id="navbarDropdown"
                                    data-bs-toggle="dropdown"
                                    aria-expanded="false"
                                >Past Editions</a>
                                <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <li>
                                        <a class="dropdown-item" href="2023/index.html">2023</a>
                                    </li>
                                </ul>
                            </li>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link js-scroll-trigger" target="_blank" href="https://www.sigsac.org/ccs/CCS2024/">ACM CCS</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Header -->
        <header class="masthead">
            <div class="container">
                <div class="intro-text">
                    <div class="intro-heading">
                        17
                        <sup>
                            <small>
                                <b>th</b>
                            </small>
                        </sup>
                        ACM Workshop on
                        <br>
                        Artificial Intelligence and Security
                    </div>
                    <div class="intro-lead-in">
                        <b>October 18th, 2024 — Salt Lake City</b>
                    </div>
                    <div class="intro-lead-in">
                        co-located with the 31st ACM Conference on Computer and Communications Security
                    </div>
                    <div class="photo-credit">
                        Photo:
                        <a target="_blank" href="https://it.wikipedia.org/wiki/Salt_Lake_City#/media/File:Salt_Lake_City_-_July_16,_2011.jpg">Wikipedia</a>
                        (License:
                        <a href="https://creativecommons.org/licenses/by/2.0/">
                            CC BY 2.0
                        </a>
                        )
                    </div>
                </div>
            </div>
        </header>
        <!-- <section id="keynote">
        <div class="container">
            <div class="row">
                <h2 class="section-heading text-uppercase">Keynotes</h2>
            </div>
            <div class="row">
                <div class="col-lg-3">
                    <center>
                        <img src="img/troncoso.jpg" class="portait">
                    </center>
                </div>
                <div class="col-lg-9 text-justify">
                    <h3 class="section-subheading">
                        <b>Title: When decentralization, security, and privacy are not friends</b>
                    </h3>
                    <details>
                        <summary>
                            <b>Carmela Troncoso, Associate Professor @ EPFL</b>
                        </summary>
                        <p>Carmela Troncoso is an Associate Professor at EPFL (Switzerland) where she heads the SPRING Lab. Her work focuses on analyzing, building, and deploying secure and privacy-preserving systems. Troncoso holds a Ph.D. in engineering from KULeuven. Her work on privacy engineering has received multiple awards, and she has been named 40 under 40 in technology by Fortune in 2020.</p>
                    </details>
                    <p>Decentralization is often seen as a main tool to achieve security and privacy. It has worked in a number of systems, for which decentralization help protect identities and data of users. Thus, it is not a surprise that a new trend of machine learning algorithms opt for decentralization to increase data privacy. In this talk, we will analyze decentralized machine learning proposals and show how they not only don’t improve privacy or robustness, but also increase the surface of attack resulting in less protection than federated alternatives.</p>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-3">
                    <center>
                        <img src="img/rodriguez.jpeg" class="portait">
                    </center>
                </div>
                <div class="col-lg-9 text-justify">
                    <h3 class="section-subheading">
                        <b>Title: Emerging challenges in securing frontier AI systems</b>
                    </h3>
                    <details>
                        <summary>
                            <b>Mikel Rodriguez, AI Red Teaming @ Google Deepmind</b>
                        </summary>
                        <p>
                            Dr. Mikel Rodriguez has spent over two decades working in the public and private sector securing the application of Artificial Intelligence in high-stakes consequential environments. At Google DeepMind, Mikel defines and leads the cross-functional AI Red and Blue “ReBl” team to ensure that foundational models are battle-tested with the rigor and scrutiny of real-world adversaries, and help drive research and tooling that will make this red-blue mindset scalable in preparation for AGI.
                            In his role as the Managing Director at MITRE Labs, Mikel built and led the AI Red Team that focuses on deployed AI systems that can be susceptible to bias in their data, attacks involving evasion, data poisoning, model replication; and the exploitation of software flaws to deceive, manipulate, compromise, and render them ineffective. Mikel’s team worked on developing methods to mitigate bias and defend against emerging ML attacks, securing the AI supply chain, and generally ensuring the trustworthiness of AI systems so they perform as intended in mission-critical environments. While at MITRE, his team in collaboration with many industry partners, published ATLAS (Adversarial Threat Landscape for AI Systems) - a knowledge base of adversary tactics, techniques, and case studies for machine learning (ML) systems based on real-world observations, demonstrations from ML red teams and security groups, and the state of the possible from academic research.  Mikel firmly believes that AI’s potential will only be realized through collaborations that help produce reliable, resilient, fair, interpretable, privacy preserving, and secure technologies.
                            Mikel received his Ph.D. in 2010 while working at University of Central Florida’s computer vision lab with professor Mubarak Shah. He then moved to Paris where he worked as a post-doctoral research fellow at INRIA.
                        </p>
                    </details>
                    <p>
                        As advanced AI assistants have become more general purpose, sophisticated and capable, they create new opportunities in a variety of fields, such as education, science and healthcare. Yet the rapid speed of progress has made it difficult to adequately prepare for, or even understand, security and privacy vulnerabilities that may emerge as a result of these new capabilities.  
                        Several foreseeable developments in advanced AI assistants including tool use, multimodality, planning and deeper reasoning, and memory have the potential to significantly expand the security and misuse risk profile of these systems. In this talk we will explore a number of best practices and future research directions that can help us better prepare society for managing these risks.
                    </p>
                    <p></p>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-3">
                    <center>
                        <img src="img/fritz.jpg" class="portait">
                    </center>
                </div>
                <div class="col-lg-9 text-justify">
                    <h3 class="section-subheading">
                        <b>Title: Trustworthy AI and A Cybersecurity Perspective on Large Language Models</b>
                    </h3>
                    <details>
                        <summary>
                            <b>Mario Fritz, Faculty @ CISPA Helmholtz Center for Information Security</b>
                        </summary>
                        <p>
                            Prof. Dr. Mario Fritz is a faculty at the CISPA Helmholtz Center for Information Security, an honorary professor at Saarland University, and a fellow of the European Laboratory for Learning and Intelligent Systems (ELLIS). Until 2018, he led a research group at the Max Planck Institute for Computer Science. Previously, he was a PostDoc at the International Computer Science Institute (ICSI) and UC Berkeley after receiving his PhD from TU Darmstadt and studying computer science at FAU Erlangen-Nuremberg. His research focuses on trustworthy artificial intelligence, especially at the intersection of information security and machine learning. He is Associate Editor of the journal "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) and has published over 100 articles in top conferences and journals. Currently, he is coordinating the Network of Excellence in AI "ELSA -- European Lighthouse on Secure and Safe AI" which is an ELLIS (https://ellis.eu/) initiative that is funded by the EU and connects universities, research institutes, and industry partners across Europe (elsa-ai.eu).
                        </p>
                    </details>
                    <p>
                        As AI technology is getting increasingly mature, we see a broad deployment of AI in many application domains. However, this increases the demands on properties related to trustworthiness like robustness, privacy, transparency, accountability as well as explainability. Besides the trustworthiness of AI, misinformation and deepfakes are becoming key concerns in terms of the negative effects that AI can have on society. I'll discuss the larger ecosystem around misinformation and different approaches to mitigate these pressing issues in the future. Finally, Large Language Models (LLMs) like GPT4 have demonstrated how AI deployment is reaching millions of users, which in turn puts a magnifying glass on some of the issues mentioned before. I'll demonstrate cybersecurity concerns and threats that emerge from the recent trend of application-integrated LLMs and AI assistants as well as sketch how future development will initiate new research challenges in this domain.
                    </p>
                    <p></p>
                </div>
            </div>
        </div>
    </div>
</section>
    <section class="bg-light" id="programme">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-justify">
                    <h2 class="section-heading text-uppercase">Programme</h2>
                    <table cellpadding="5">
                        <p>The following times are on CET (UTC +1).</p>
                        <tr>
                            <td class="orga" width="120px">09:00&ndash;9:15</td>
                            <td class="orga">Opening and Welcome</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">9:15&ndash;10:00</td>
                            <td class="orga uline">Keynote 1</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">When decentralization, security, and privacy are not friends</em>
                                <br>
                                <b>Carmela Troncoso</b>
                                , Associate Professor @ EPFL
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">10:00&ndash;10:20</td>
                            <td class="orga">Coffee break</td>
                        </tr>
                        <tr>
                            <td class="orga">10:20-11:00</td>
                            <td class="orga uline">Spotlights</td>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">When Side-Channel Attacks Break the Black-Box Property of Embedded Artificial Intelligence</em>
                                    <br>
                                    <b>Authors</b>
                                    : Benoit Coqueret (Univ. Rennes, Inria), Mathieu Carbone (Thales ITSEF), Olivier Sentieys (Univ. Rennes, Inria), Gabriel Zaid (Thales ITSEF)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Lookin' Out My Backdoor! Investigating Backdooring Attacks Against DL-driven Malware Detectors</em>
                                    <br>
                                    <b>Authors</b>
                                    : Mario D'Onghia (Politecnico di Milano), Federico Di Cesare (Politecnico di Milano), Luigi Gallo (Cyber Security Lab, Telecom Italia), Michele Carminati (Politecnico di Milano), Mario Polino (Politecnico di Milano), Stefano Zanero (Politecnico di Milano)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</em>
                                    <br>
                                    <b>Authors</b>
                                    : Sahar Abdelnabi (CISPA Helmholtz Center for Information Security), Kai Greshake (Saarland University, sequire technology GmbH), Shailesh Mishra (Saarland University), Christoph Endres (sequire technology GmbH), Thorsten Holz (CISPA Helmholtz Center for Information Security), Mario Fritz (CISPA Helmholtz Center for Information Security)
                                </td>
                            </tr>
                            <tr>
                                <td></td>
                                <td>
                                    <em class="paper">Canaries and Whistles: Resilient Drone Communication Networks with (or without) Deep Reinforcement Learning</em>
                                    <br>
                                    <b>Authors</b>
                                    : Chris Hicks (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing Institute), Myles Foley (Imperial College London), Thomas Davies (The Alan Turing Institute), Kate Highnam (Imperial College London), Tim Watson (The Alan Turing Institute)
                                </td>
                            </tr>
                        </tr>
                        <tr>
                            <td class="orga">11:00&ndash;12:00</td>
                            <td class="orga uline">Poster session 1</td>
                        </tr>
                        <tr>
                            <td class="orga">12:00&ndash;13:30</td>
                            <td class="orga">Lunch</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">13:30&ndash;14:15</td>
                            <td class="orga uline">
                                Keynote 2
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Emerging challenges in securing frontier AI systems</em>
                                <br>
                                <b>Mikel Rodriguez</b>
                                , AI Red Teaming @ Google Deepmind
                            </td>
                        </tr>
                        <tr>
                            <td class="orga">14:15&ndash;14:45</td>
                            <td class="orga">Break</td>
                        </tr>
                        <tr>
                            <td class="orga" width="120px">14:45&ndash;15:30</td>
                            <td class="orga uline">
                                Keynote 3
                                <br>
                            </td>
                        </tr>
                        <tr>
                            <td></td>
                            <td>
                                <em class="paper">Trustworthy AI and A Cybersecurity Perspective on Large Language Models</em>
                                <br>
                                <b>Mario Fritz</b>
                                , Faculty @ CISPA Helmholtz Center for Information Security
                            </td>
                        </tr>
                    </tr>
                    <tr>
                        <td class="orga">15:30&ndash;16:30</td>
                        <td class="orga uline">Poster session 2</td>
                    </tr>
                    <tr>
                        <td class="orga">16:30&ndash;16:45</td>
                        <td class="orga">Closing remarks</td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <section id="accepted">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-justify">
                <h2 class="section-heading text-uppercase">Accepted Papers</h2>
                <p>
                    You can find the accepted papers in the
                    <a href="https://dl.acm.org/doi/proceedings/10.1145/3605764">proceedings</a>
                    .
                </p>
                <strong>Privacy-Preserving Machine Learning (Poster session 1)</strong>
                <table cellpadding="5">
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Differentially Private Logistic Regression with Sparse Solutions</em>
                            <br>
                            <b>Authors</b>
                            : Amol Khanna (Booz Allen Hamilton), Fred Lu (Booz Allen Hamilton; University of Maryland, Baltimore County), Edward Raff (Booz Allen Hamilton; University of Maryland, Baltimore County), Brian Testa (Air Force Research Laboratory)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Equivariant Differentially Private Deep Learning: Why DP-SGD Needs Sparser Models</em>
                            <br>
                            <b>Authors</b>
                            : Florian A. Hölzl (Artifical Intelligence in Medicine, Technical University of Munich), Daniel Rueckert (Artifical Intelligence in Medicine, Technical University of Munich), Georgios Kaissis (Artifical Intelligence in Medicine, Technical University of Munich)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Probing the Transition to Dataset-Level Privacy in ML Models Using an Output-Specific and Data-Resolved Privacy Profile</em>
                            <br>
                            <b>Authors</b>
                            : Tyler LeBlond (Booz Allen Hamilton), Joseph Munoz (Booz Allen Hamilton), Fred Lu (Booz Allen Hamilton), Maya Fuchs (Booz Allen Hamilton), Elliot Zaresky-Williams (Booz Allen Hamilton), Edward Raff (Booz Allen Hamilton), Brian Testa (Air Force Research Laboratory)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Information Leakage from Data Updates in Machine Learning Models</em>
                            <br>
                            <b>Authors</b>
                            : Tian Hui (The University of Melbourne), Farhad Farokhi (University of Melbourne), Olga Ohrimenko (The University of Melbourne)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Membership Inference Attacks Against Semantic Segmentation Models</em>
                            <br>
                            <b>Authors</b>
                            : Tomas Chobola (Helmholtz AI), Dmitrii Usynin (Department of Computing, Imperial College London; Artificial Intelligence in Medicine and Healthcare, TUM), Georgios Kaissis (Artificial Intelligence in Medicine and Healthcare, TUM; Institute for Machine Learning in Biomedical Imaging, Helmholtz Zentrum München; Department of Computing, Imperial College London)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Utility-preserving Federated Learning</em>
                            <br>
                            <b>Authors</b>
                            : Reza Nasirigerdeh (Technical University of Munich), Daniel Rueckert (Technical University of Munich), Georgios Kaissis (Technical University of Munich)
                        </td>
                    </tr>
                </table>
                <strong>Machine Learning for Cybersecurity (Poster session 1)</strong>
                <table cellpadding="5">
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Certified Robustness of Static Deep Learning-based Malware Detectors against Patch and Append Attacks</em>
                            <br>
                            <b>Authors</b>
                            : Daniel Gibert (CeADAR, University College Dublin), Giulio Zizzo (IBM Research Europe), Quan Le (CeADAR, University College Dublin)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">AVScan2Vec: Feature Learning on Antivirus Scan Data for Production-Scale Malware Corpora</em>
                            <br>
                            <b>Authors</b>
                            : Robert J. Joyce (Booz Allen Hamilton, University of Maryland Baltimore County), Tirth Patel (University of Maryland Baltimore County), Charles Nicholas (University of Maryland Baltimore County), Edward Raff (Booz Allen Hamilton, University of Maryland Baltimore County)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Drift Forensics of Malware Classifiers</em>
                            <br>
                            <b>Authors</b>
                            : Theo Chow (King's College London), Zeliang Kan (King's College London), Lorenz Linhardt (Technische Universität Berlin), Lorenzo Cavallaro (University College London), Daniel Arp (Technische Universität Berlin), Fabio Pierazzi (King's College London)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Lookin' Out My Backdoor! Investigating Backdooring Attacks Against DL-driven Malware Detectors</em>
                            <br>
                            <b>Authors</b>
                            : Mario D'Onghia (Politecnico di Milano), Federico Di Cesare (Politecnico di Milano), Luigi Gallo (Cyber Security Lab, Telecom Italia), Michele Carminati (Politecnico di Milano), Mario Polino (Politecnico di Milano), Stefano Zanero (Politecnico di Milano)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Reward Shaping for Happier Autonomous Cyber Security Agents</em>
                            <br>
                            <b>Authors</b>
                            : Elizabeth Bates (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing Institute), Chris Hicks (The Alan Turing Institute)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors</em>
                            <br>
                            <b>Authors</b>
                            : Biagio Montaruli (SAP Security Research, EURECOM), Luca Demetrio (Università degli Studi di Genova), Maura Pintor (University of Cagliari), Battista Biggio (University of Cagliari), Luca Compagna (SAP Security Research), Davide Balzarotti (EURECOM)
                        </td>
                    </tr>
                </table>
                <strong>Machine Learning Security (Poster session 2)</strong>
                <table cellpadding="5">
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Certifiers Make Neural Networks Vulnerable to Availability Attacks</em>
                            <br>
                            <b>Authors</b>
                            : Tobias Lorenz (CISPA Helmholtz Center for Information Security), Marta Kwiatkowska (University of Oxford), Mario Fritz (CISPA Helmholtz Center for Information Security)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</em>
                            <br>
                            <b>Authors</b>
                            : Sahar Abdelnabi (CISPA Helmholtz Center for Information Security), Kai Greshake (Saarland University, sequire technology GmbH), Shailesh Mishra (Saarland University), Christoph Endres (sequire technology GmbH), Thorsten Holz (CISPA Helmholtz Center for Information Security), Mario Fritz (CISPA Helmholtz Center for Information Security)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Canaries and Whistles: Resilient Drone Communication Networks with (or without) Deep Reinforcement Learning</em>
                            <br>
                            <b>Authors</b>
                            : Chris Hicks (The Alan Turing Institute), Vasilios Mavroudis (The Alan Turing Institute), Myles Foley (Imperial College London), Thomas Davies (The Alan Turing Institute), Kate Highnam (Imperial College London), Tim Watson (The Alan Turing Institute)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">The Adversarial Implications of Variable-Time Inference</em>
                            <br>
                            <b>Authors</b>
                            : Dudi Biton (Ben Gurion University of the Negev), Aditi Misra (University of Toronto), Efrat Levy (Ben Gurion University of the Negev), Jaidip Kotak (Ben Gurion University of the Negev), Ron Bitton (Ben Gurion University of the Negev), Roei Schuster (Wild Moose), Nicolas Papernot (University of Toronto and Vector Institute), Yuval Elovici (Ben Gurion University of the Negev), Ben Nassi (Cornell Tech)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Dictionary Attack on IMU-based Gait Authentication</em>
                            <br>
                            <b>Authors</b>
                            : Rajesh Kumar (Bucknell University), Can Isik (Syracuse University), CHILUKURI MOHAN (Syracuse University)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">When Side-Channel Attacks Break the Black-Box Property of Embedded Artificial Intelligence</em>
                            <br>
                            <b>Authors</b>
                            : Benoit Coqueret (Univ. Rennes, Inria), Mathieu Carbone (Thales ITSEF), Olivier Sentieys (Univ. Rennes, Inria), Gabriel Zaid (Thales ITSEF)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Task-Agnostic Safety for Reinforcement Learning</em>
                            <br>
                            <b>Authors</b>
                            : Md Asifur Rahman (Wake Forest University), Sarra Alqahtani (Wake Forest University)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery</em>
                            <br>
                            <b>Authors</b>
                            : Erik Imgrund (SAP Security Research), Tom Ganz (SAP Security Research), Martin Härterich (SAP Security Research), Niklas Risse (Max-Planck-Institute for Security and Privacy), Lukas Pirch (Technische Universität Berlin), Konrad Rieck (Technische Universität Berlin)
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>
                            <em class="paper">Measuring Equality in Machine Learning Security Defenses: A Case Study in Speech Recognition</em>
                            <br>
                            <b>Authors</b>
                            : Luke E. Richards (University of Maryland, Baltimore County), Edward Raff (University of Maryland, Baltimore County; Booz Allen Hamilton), Cynthia Matuszek (University of Maryland, Baltimore County)
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </section> -->
        <section id="cfp">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-justify">
                        <h2 class="section-heading text-uppercase">Call for Papers</h2>
                        <h3 class="section-subheading">Important Dates</h3>
                        <ul>
                            <li>
                                Paper submission deadline:
                                <s>June 21st</s>
                                July 7th, 2024, 11:59 PM (all deadlines are AoE, UTC-12)
                            </li>
                            <li>
                                Reviews due:
                                <s>July 19th</s>
                                July 31st, 2024
                            </li>
                            <li>
                                Review Released and Acceptance notification:
                                <s>August 2nd</s>
                                August 6th, 2024
                            </li>
                            <li>Camera ready due:
                                <s>August 22nd</s>
                                August 30th, 2024
                            </li>
                            <li>Workshop day: October 18th, 2024</li>
                        </ul>
                        <h3 class="section-subheading">Overview</h3>
                        <p>
                            Recent years have seen a dramatic increase in applications of Artificial Intelligence (AI), Machine Learning (ML), and data mining to security and privacy problems. The analytic tools and intelligent behavior provided by these techniques make AI and ML increasingly important for autonomous real-time analysis and decision making in domains with a wealth of data or that require quick reactions to constantly changing situations. The use of learning methods in security-sensitive domains, in which adversaries may attempt to mislead or evade intelligent machines, creates new frontiers for security research. The recent widespread adoption of “deep learning” techniques, whose security properties are difficult to reason about directly, has only added to the importance of this research. In addition, data mining and machine learning techniques create a wealth of privacy issues, due to the abundance and accessibility of data. The AISec workshop provides a venue for presenting and discussing new developments in the intersection of security and privacy with AI and ML.
                        </p>
                        <h3 class="section-subheading">Topics of Interest</h3>
                        <p>Topics of interest include (but are not limited to):</p>
                        <p>
                            <b>Theoretical topics related to security</b>
                        </p>
                        <ul>
                            <li>Adversarial learning</li>
                            <li>Security of deep learning systems</li>
                            <li>Robust statistics</li>
                            <li>Learning in games</li>
                            <li>Economics of security</li>
                            <li>Differential privacy</li>
                        </ul>
                        <p>
                            <b>Security applications</b>
                        </p>
                        <ul>
                            <li>Computer forensics</li>
                            <li>Spam detection</li>
                            <li>Phishing detection and prevention</li>
                            <li>Botnet detection</li>
                            <li>Intrusion detection and response</li>
                            <li>Malware identification and analysis</li>
                            <li>Data anonymization/de-anonymization</li>
                            <li>Security in social networks</li>
                            <li>Big data analytics for security</li>
                            <li>User authentication</li>
                        </ul>
                        <p>
                            <b>Security-related AI problems</b>
                            <p>
                                <ul>
                                    <li>Distributed inference and decision making for security</li>
                                    <li>Secure multiparty computation and cryptographic approaches</li>
                                    <li>Model confidentiality</li>
                                    <li>Privacy-preserving data mining</li>
                                    <li>Adaptive side-channel attacks</li>
                                    <li>Design and analysis of CAPTCHAs</li>
                                    <li>AI approaches to trust and reputation</li>
                                    <li>Vulnerability testing through intelligent probing (e.g. fuzzing)</li>
                                    <li>Content-driven security policy management & access control</li>
                                    <li>Techniques and methods for generating training and test sets</li>
                                    <li>Anomalous behavior detection (e.g. for the purpose of fraud detection)</li>
                                    <li>AI Misuse (e.g., Large Language Models for automated hacking, misinformation, deepfakes)</li>
                                    <li>Safety and ethical issues of Generative AI</li>
                                </ul>
                                <h3 class="section-subheading">Submission Guidelines</h3>
                                <p>
                                    We invite the following types of papers:
                                    <ul>
                                        <li>
                                            <b>Original research papers</b>
                                            on any topic in the intersection of AI or machine learning
                            with security, privacy, or related areas.
                                        </li>
                                        <li>
                                            <b>Position and open-problem papers</b>
                                            discussing the relationship of AI or machine
                            learning to security or privacy. Submitted papers of this type may not substantially overlap
                            with papers that have been published previously or that are simultaneously submitted to a
                            journal or conference/workshop proceedings.
                                        </li>
                                        <li>
                                            <b>Systematization-of-knowledge papers</b>
                                            , which should distill the AI or machine learning
                            contributions of a previously-published series of security papers.
                                        </li>
                                    </ul>
                                </p>
                                <p>
                                    The authors can specify the paper type in the submission form. Paper submissions must be at most
                        10 pages in double-column ACM format, excluding the bibliography and well-marked appendices, and
                        at most 12 pages overall.
                        Papers should be in LaTeX and we recommend using the ACM format. This format is required for the
                        camera-ready version. Please follow the main CCS formatting instructions (except with page
                        limits as described above). In particular, we recommend using the sigconf template, which can be
                        downloaded from
                                    <a href="https://www.acm.org/publications/proceedings-template" target="_blank">https://www.acm.org/publications/proceedings-template</a>
                                    . Accepted papers
                        will be published by the ACM Digital Library and/or ACM Press. Committee members are not
                        required to read the appendices, so the paper should be intelligible without them.
                                    <u>Submissions must be in English and properly anonymized.</u>
                                </p>
                                <h3 class="section-subheading">Submission Site</h3>
                                <p>
                                    Submission link:
                                    <a href="https://aisec2024.hotcrp.com" target="_blank">https://aisec2024.hotcrp.com</a>
                                    .
                                </p>
                                <p>
                                    All accepted submissions will be presented at the workshop as posters. Accepted papers 
                        will be selected for presentation as spotlights based on their review score and novelty. 
                        Nonetheless, all accepted papers should be considered as having equal importance and 
                        will be included in the ACM workshop proceedings.
                                </p>
                                <p>
                                    One author of each accepted paper is required to attend the workshop and present the paper for
                        it to be included in the proceedings.
                                </p>
                                <p>
                                    For any questions, please contact one the workshop organizers at
                                    <a href="mailto:maura.pintor@unica.it">maura.pintor@unica.it</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </section>
            </section>
            <section id="award">
                <div class="container">
                    <div class="col-lg-12 text-justify">
                        <h2 class="section-heading text-uppercase">Best Paper Award</h2>
                        <p>
                            As in the previous editions of this workshop, we would honor outstanding contributions.
                        To this end, we will award the best paper, selected by the reviewers
                        among all the submitted papers.
                        </p>
                        <p>
                            The 2023 AISec Best Paper Award was given to:
                            <br>
                            <strong>Sahar Abdelnabi</strong>
                            (CISPA Helmholtz Center for Information Security),
                            <strong>Kai Greshake</strong>
                            (Saarland University, sequire technology GmbH),
                            <strong>Shailesh Mishra</strong>
                            (Saarland University),
                            <strong>Christoph Endres</strong>
                            (sequire technology GmbH),
                            <strong>Thorsten Holz</strong>
                            (CISPA Helmholtz Center for Information Security),
                            <strong>Mario Fritz</strong>
                            (CISPA Helmholtz Center for Information Security)
                        for the paper
                            <strong>Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</strong>
                            .
                        </p>
                    </div>
                </div>
            </section>
            <section id="committee" class="bg-light">
                <div class="container">
                    <div class="row">
                        <div class="col-lg-12 text-left">
                            <h2 class="section-heading text-uppercase">Committee</h2>
                            <h3 class="section-subheading">Workshop Chairs</h3>
                            <ul class="noindent">
                                <li>
                                    <a href="https://maurapintor.github.io/" target="_blank">Maura Pintor</a>
                                    ,
                            University of Cagliari, Italy
                                </li>
                                <li>
                                    <a href="https://jungyhuk.github.io/" target="_blank">Xinyun Chen</a>
                                    , Google DeepMind, USA
                                </li>
                                <li>
                                    <a href="https://jagielski.github.io" target="_blank">Matthew Jagielski</a>
                                    , Google LLC,
                            USA
                                </li>
                            </ul>
                            <h3 class="section-subheading">Steering Committee</h3>
                            <ul class="noindent">
                                <li>
                                    <a href="http://theory.stanford.edu/~dfreeman/" target="_blank">David Freeman</a>
                                    , Facebook,
                            Inc.
                                </li>
                                <li>
                                    <a href="https://cis.unimelb.edu.au/people/staff.php?person_ID=20074/" target="_blank">Benjamin Rubinstein</a>
                                    , University of Melbourne
                                </li>
                                <li>
                                    <a href="https://pralab.diee.unica.it/en/BattistaBiggio/" target="_blank">
                                        Battista
                                Biggio
                                    </a>
                                    , University of Cagliari & PluribusOne
                                </li>
                            </ul>
                            <h3 class="section-subheading">Program Committee</h3>
                            <div class="row">
                                <div class="col">
                                    <ul class="noindent">
                                        <li>Abbas Yazdinejad (University of Guelph, Canada)</li>
                                        <li>Achin (Ace) Kulshrestha (Google Inc.)</li>
                                        <li>Aideen Fay (Microsoft)</li>
                                        <li>Alessandro Brighente (University of Padova)</li>
                                        <li>Alessandro Erba (Karlsruhe Institute of Technology)</li>
                                        <li>Alessandro Sanna (University Of Cagliari)</li>
                                        <li>Ambrish Rawat (IBM Research)</li>
                                        <li>Andrew Cullen (University of Melbourne)</li>
                                        <li>Andy Applebaum (Apple)</li>
                                        <li>Angelo Sotgiu (University of Cagliari)</li>
                                        <li>Annalisa Appice (University of Bari Aldo Moro)</li>
                                        <li>Anshuman Suri (University of Virginia)</li>
                                        <li>Antonio Emanuele Cinà (University of Genoa)</li>
                                        <li>Arjun Bhagoji (University of Chicago)</li>
                                        <li>Arnav Garg (Microsoft)</li>
                                        <li>Azqa Nadeem (University of Twente)</li>
                                        <li>Bailey Kacsmar (University of Alberta)</li>
                                        <li>Balachandra Shanabhag (Cohesity)</li>
                                        <li>Benjamin M. Ampel (Georgia State University)</li>
                                        <li>Bhavna Soman (Amazon Web Services)</li>
                                        <li>Bobby Filar (Sublime Security)</li>
                                        <li>Boyang Zhang (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Brad Miller (X Corp)</li>
                                        <li>Chawin Sitawarin (Meta)</li>
                                        <li>Christian Wressnegger (Karlsruhe Institute of Technology)</li>
                                        <li>Clarence Chio (UC Berkeley)</li>
                                        <li>Daniel Gibert (University College Dublin, CeADAR)</li>
                                        <li>Daniele Canavese (IRIT)</li>
                                        <li>Daniele Friolo (Sapienza University of Rome)</li>
                                        <li>Daniele Angioni (University of Cagliari)</li>
                                        <li>David Pape (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Diego Soi (University of Cagliary)</li>
                                        <li>Dongdong She (Hong Kong University of Science and Technology)</li>
                                        <li>Dorjan Hitaj (Sapienza University of Rome)</li>
                                        <li>Edoardo Debenedetti (ETH Zurich)</li>
                                        <li>Edward Raff (Booz Allen Hamiltion)</li>
                                        <li>Erwin Quiring (Ruhr University Bochum and ICSI)</li>
                                        <li>Eva Giboulot (Linkmedia - INRIA Rennes)</li>
                                        <li>Fabio Brau (Scuola Superiore Sant'Anna)</li>
                                        <li>Fabio De Gaspari (Sapienza University of Rome)</li>
                                        <li>Francesco Flammini (IDSIA USI-SUPSI)</li>
                                        <li>Giorgio Piras (University of Cagliari)</li>
                                        <li>Giorgio Severi (Northeastern University)</li>
                                        <li>Giovanni Cherubin (Microsoft)</li>
                                        <li>Giovanni Apruzzese (University of Liechtenstein)</li>
                                        <li>Giulio Rossolini (Scuola Superiore Sant'Anna)</li>
                                        <li>Giulio Zizzo (IBM Research)</li>
                                        <li>Giuseppina Andresini (University of Bari Aldo Moro)</li>
                                        <li>Hamid Bostani (Radboud University, The Netherlands)</li>
                                        <li>Hari Venugopalan (University of California, Davis)</li>
                                        <li>Ilias Tsingenopoulos (DistriNet, KU Leuven)</li>
                                        <li>James Hu (University of Arizona)</li>
                                        <li>Javier Carnerero Cano (IBM Research Europe/Imperial College London)</li>
                                        <li>Joel Frank (Meta)</li>
                                        <li>John Holodnak (MIT Lincoln Laboratory)</li>
                                        <li>Jonas Möller (TU Berlin)</li>
                                        <li>Jonas Ricker (Ruhr University Bochum)</li>
                                        <li>Jose Maria de Fuentes (Universidad Carlos III de Madrid)</li>
                                        <li>Julien Piet (UC Berkeley)</li>
                                        <li>Junhao Dong (Nanyang Technological University)</li>
                                        <li>Kathrin Grosse (EPFL)</li>
                                        <li>Kexin Pei (The University of Chicago)</li>
                                    </ul>
                                </div>
                                <div class="col">
                                    <ul class="noindent">
                                        <li>Konrad Rieck (TU Berlin)</li>
                                        <li>LE MERRER Erwan (Inria, France)</li>
                                        <li>Lea Schönherr (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Lei Ma (The University of Tokyo / University of Alberta)</li>
                                        <li>Leonardo Regano (University Of Cagliari)</li>
                                        <li>Lorenzo Cazzaro (Università Ca' Foscari Venezia)</li>
                                        <li>Lorenzo Pisu (University Of Cagliari)</li>
                                        <li>Luca Demetrio (University of Genoa)</li>
                                        <li>Luis Muñoz-González (Telefónica Research)</li>
                                        <li>Luke Richards (University of Maryland, Baltimore County)</li>
                                        <li>Maria Rigaki (Czech Technical University in Prague)</li>
                                        <li>Markus Dürmuth (Leibniz University Hannover)</li>
                                        <li>Marta Catillo (Università degli Studi del Sannio)</li>
                                        <li>Matthew Jagielski (Google Research)</li>
                                        <li>Maura Pintor (University of Cagliari)</li>
                                        <li>Mauro Conti (University of Padua)</li>
                                        <li>Maximilian Noppel (Karlsruhe Institute of Technology)</li>
                                        <li>Melody Wolk (Apple)</li>
                                        <li>Milenko Drinic (Microsoft Corporation)</li>
                                        <li>Muhammad Zaid Hameed (IBM Research Europe, Ireland)</li>
                                        <li>Ozan Özdenizci (Montanuniversität Leoben)</li>
                                        <li>Pablo Moriano (Oak Ridge National Laboratory)</li>
                                        <li>Patrick Dwyer (Apple, Inc)</li>
                                        <li>Pavel Laskov (University of Liechtenstein)</li>
                                        <li>Pooria Madani (Ontario Tech University)</li>
                                        <li>Pratyusa K. Manadhata (Meta)</li>
                                        <li>Quan Le (CeADAR, University College Dublin)</li>
                                        <li>SHRIKANT TANGADE (University of Padova, Italy & CHRIST University, India)</li>
                                        <li>Sahar Abdelnabi (Microsoft)</li>
                                        <li>Sam Bretheim (Craigslist)</li>
                                        <li>Sanghyun Hong (Oregon State University)</li>
                                        <li>Savino Dambra (Norton Research Group)</li>
                                        <li>Scott Coull (Google)</li>
                                        <li>Shae McFadden (King's College London & The Alan Turing Institute)</li>
                                        <li>Shujiang Wu (F5. Inc)</li>
                                        <li>Silvia Lucia Sanna (University of Cagliari)</li>
                                        <li>Simon Oya (The University of British Columbia (UBC))</li>
                                        <li>Simos Gerasimou (University of York. UK)</li>
                                        <li>Sivanarayana Gaddam (Cohesity Inc)</li>
                                        <li>Sizhe Chen (UC Berkeley)</li>
                                        <li>Theo Chow (King's College London)</li>
                                        <li>Thorsten Eisenhofer (TU Berlin)</li>
                                        <li>Tianhao Wang (University of Virginia)</li>
                                        <li>Tobias Lorenz (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Vera Rimmer (KU Leuven)</li>
                                        <li>Vikash Sehwag (Sony AI)</li>
                                        <li>Vinod P. (University of Padua, Italy)</li>
                                        <li>Wenjun Zhu (Zhejiang University)</li>
                                        <li>Wenxin Ding (University of Chicago)</li>
                                        <li>Xiaofei Xie (Singapore Management University)</li>
                                        <li>Xiaoyu Ji (Zhejiang University)</li>
                                        <li>Xin Fan Guo (King's College London)</li>
                                        <li>Xinyue Shen (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Xinyun Chen (Google DeepMind)</li>
                                        <li>Yang Zhang (CISPA Helmholtz Center for Information Security)</li>
                                        <li>Yash Vekaria (University of California, Davis)</li>
                                        <li>Yue Zhao (Institute of Information Engineering, Chinese Academy of Sciences)</li>
                                        <li>Yufei Han (INRIA)</li>
                                        <li>Zeliang Kan (King's College London)</li>
                                        <li>Zied Ben Houidi (Huawei Technologies Co. Ltd.)</li>
                                        <li>Ziqi Yang (Zhejiang University)</li>
                                    </ul>
                                </div>
                            </div>
                            <p>
                                <!-- We are currently looking for reviewers. Contact
                                <a href="mailto:maura.pintor@unica.it">maura.pintor@unica.it</a>
                                if you want to be involved. -->
                                Thanks for those who contacted us to help with the reviews!
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <!-- Footer -->
            <footer>
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <span class="copyright">Copyright © AISec 2024</span>
                            <br>
                        </div>
                        <div class="col-md-6">
                            Support kindly provided by the
                            <a href="https://www.unica.it/unica/en/homepage.page/" target="_blank">University of Cagliari</a>
                            and by the
                            <a href="https://elsa-ai.eu" target="_blank">
                                ELSA project
                            </a>
                            .
                            <br>
                            <img src="https://web.unica.it/UserFiles/File/Utenti/verdeoro/unica_800_black.png" height="50em" style="margin: 10px;">
                            <img src="img/elsa_logo_RGB_twocolor-300x272.png" height="50em" style="margin: 10px;">
                        </div>
                    </div>
                </div>
            </footer>
            <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
            <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe" crossorigin="anonymous"></script>
            <script src="js/agency.min.js"></script>
        </body>
    </html>
